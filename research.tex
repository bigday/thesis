\chapter{Approach}
% TODO: remember to justify the choices made
% also compare different possibilities

\section{Getting point cloud data}

% TODO: explain RGB-D
% TODO: avoid using an abbreviation altogether?

The OpenNI library \citep{OpenNI}
was used for data acquisition. The actual sensor used was Microsoft Kinect.

\section{Body part segmentation}

Before any attempts at human body reconstruction can be made, the body needs to be detected from the RGB-D image. 

The NITE middleware for OpenNI \citep{NITE}
includes functions for person detection. Moreover, NITE has the capability to generate a skeleton representation of human users.

As the skeleton representation is available, it was used to aid in recosntructing the body model.

Using the skeleton data, we segment the point cloud according to body parts.

The body parts used were chosen according to what the NITE skeleton allowed. Thus the following segments were used:

\fixme{TODO: what do we really have? what are the right English terms?
legs, feet, forearms, shoulders, head, torso, hip}

\section{Point cloud alignment}

The na√Øve approach to modeling uses data only from a single frame. However, this is unsatisfactory as in practice only less than a half (e.g. the front part) of a human can be seen at once. Another consideration is that the data tends to be noisy and inaccurate. Accumulating data over time makes it possible to remove some of the noise and improve accuracy.

To allow for combining data from multiple frames, the observations (point clouds) need to be aligned one way or another. Methods introduced in \autoref{literature.alignment} were available, each with their own trade-offs.

\fixme{write more about this when the best approach is actually chosen}

\section{Mesh generation}

\fixme{Alternative approaches, including the following}

\subsection{Voxel grid}

One possible approach is to use a voxel grid not unlike the one Kinect Fusion \citep{} uses. This allows generating meshes representing arbitrary shapes.

To evaluate the approach, a prototype was built on top of Kinfu\footnote{Kinfu is an open source implementation of Kinect Fusion \citep{newcombe2011kinectfusion
}. It is included in the Point Cloud Library \citep{PCL}.}. Since the point clouds were already segmented by body part, it was possible to create recordings that only include a single body part. These recordings could then be played back and used as input for Kinfu.

The working hypothesis was that each body part could be treated as a static object, and that Kinfu should do quite well at modeling them. Notably there's little difference between the camera moving (as is the case in Kinect Fusion) and the object moving. If the background is filtered out, the result is similar. This made for the case that running the Kinect Fusion algorithm in parallel to each body part could give reasonably good results.

\subsection{Parametric surfaces}

Another approach is to use the information readily available about the body parts being modeled. Instead of allowing arbitrary shapes, the space of possible shapes can be limited to what the body parts tend to look like.

As the very first prototype, a simple cylinder approximation was used. A cylinder was fitted to the point cloud of a body part, and colored according to its average color. This was good for testing the segmentation and getting a general idea of how accurate the skeleton is. Some corner cases were also found using this prototype.

Obviously, a more human-like model was required.

\section{Texturing}

\fixme{Write something here once I've done something...}
